bool load_frame(const std::string file_path, int* width_out, int* height_out, std::vector<std::uint8_t> *data_out) {

	// Format context holds data of media operations using avformat
	AVFormatContext* av_format_ctx = avformat_alloc_context();
	const char* filename = "C:\\Users\\bripl\\source\\repos\\MediaServer\\out\\build\\x64-debug\\Server\\QA Workshop Test Framework-20140129 1421-1.mp4";
	if (!av_format_ctx) {
		std::cout << "Couldn't init format context" << std::endl;
		return false;
	}
	// Try to open file and populate context. Reads file header based on file type to get properties
	if (avformat_open_input(&av_format_ctx, filename, NULL, NULL) != 0) {
		std::cout << "Couldn't open video file" << std::endl;
		return false;
	}


	int video_stream_index = -1;
	int audio_stream_index = -1;

	AVCodecParameters* video_codec_params;
	const AVCodec* video_codec;

	AVCodecParameters* audio_codec_params;
	const AVCodec* audio_codec;

	std::cout << av_format_ctx->streams << std::endl;

	// Iterate through streams in context to get index of video and audio streams
	for (int i = 0; i < av_format_ctx->nb_streams; ++i) {
		// Get codec params from stream
		auto codec_params = av_format_ctx->streams[i]->codecpar;
		// Get codec for stream if it exists
		auto codec = avcodec_find_decoder(codec_params->codec_id);

		if (!codec) {
			std::cout << "Codec " << codec_params->codec_id << " not found for present stream!" << std::endl;
			continue;
		}
		// If we find video stream, init video codec properties
		if (codec->type == AVMEDIA_TYPE_VIDEO) {
			std::cout << "Found video codec: " << codec->type << std::endl;
			video_stream_index = i;
			video_codec = codec;
			video_codec_params = codec_params;
			continue;
		}
		// If we find audio stream, init audio codec properties
		else if (codec_params->codec_type == AVMEDIA_TYPE_AUDIO) {
			std::cout << "Found audio codec: " << codec->type << std::endl;
			audio_stream_index = i;
			audio_codec = codec;
			audio_codec_params = codec_params;
			continue;
		}

	}
	if (video_stream_index < 0) {
		std::cout << "Unable to find a valid video stream!" << std::endl;
		return false;
	}

	// Create codec context and open codec if possible
	AVCodecContext* video_codec_context = avcodec_alloc_context3(video_codec);
	if (!video_codec_context) {
		std::cout << "Unable to create video codec context!" << std::endl;
		return false;
	}
	if (avcodec_parameters_to_context(video_codec_context, video_codec_params) < 0) {
		std::cout << "Unable to initiate video codec context!" << std::endl;
		return false;
	}
	if (avcodec_open2(video_codec_context, video_codec, NULL) < 0) {
		std::cout << "Couldn't open the video codec!" << std::endl;
		return false;
	}


	// Try to get frame/packets
	// format context, stream_indexes, codec_context, 
	AVFrame* av_frame = av_frame_alloc();
	if (!av_frame) {
		std::cout << "Could not allocate frame!" << std::endl;
		return false;
	}

	AVPacket* av_packet = av_packet_alloc();
	if (!av_packet) {
		std::cout << "Could not allocate packet!" << std::endl;
		return false;
	}

	// Packet may contain several frames
	while (av_read_frame(av_format_ctx, av_packet) >= 0) {

		int stream_index = av_packet->stream_index;
		// Filter out packets that arent video packets
		if (stream_index == video_stream_index) {
			// Decode video packet with video codec
			// Send packet to decoder
			int response = avcodec_send_packet(video_codec_context, av_packet);

			if (response < 0) {
				std::cout << "Failed to decode video packet!" << std::endl;
				return false;
			}
			// Receive frame from decoder and put it in our frame
			response = avcodec_receive_frame(video_codec_context, av_frame);
			if (response == AVERROR(EAGAIN) || response == AVERROR_EOF) {
				continue;
			}
			else if (response < 0) {
				std::cout << "Failed to decode packet!" << std::endl;
				return false;
			}
		}
		else if (stream_index == audio_stream_index) {
			continue;
		}
		else {
			continue;
		}
		av_packet_unref(av_packet);
	}

	// Scaling context to transform data from YUV to RBG0
	SwsContext* sws_scaler_ctx = sws_getContext(av_frame->width, av_frame->height, video_codec_context->pix_fmt, 
		av_frame->width, av_frame->height, AV_PIX_FMT_RGB0, SWS_BILINEAR, NULL, NULL, NULL);

	if (!sws_scaler_ctx) {
		std::cout << "Could not initialize scaler context!" << std::endl;
	}

	// Vector holds rgb pixels. 4 bytes per pixel for R-G-B-A data
	std::vector<std::uint8_t> data(av_frame->width * av_frame->height * 4);
	// Buffer to be populated by scaler
	std::array<std::uint8_t*, 4> dest_buffer = {&data[0], NULL, NULL, NULL};
	// Scale/ reformat data into RGBA buffer
	sws_scale(sws_scaler_ctx, av_frame->data, av_frame->linesize, 0, av_frame->height, &dest_buffer[0], NULL);
	// Free the scalar context
	sws_freeContext(sws_scaler_ctx);

	*width_out = av_frame->width;
	*height_out = av_frame->height;
	*data_out = data;

	avformat_close_input(&av_format_ctx);
	avformat_free_context(av_format_ctx);
	avcodec_free_context(&video_codec_context);
	//avcodec_free_context(&audio_codec_context)
	av_frame_free(&av_frame);
	av_packet_free(&av_packet);

	return true;
}